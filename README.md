# Overview

'80% of time in data science and analysis is spent data cleaning'

This includes:</br>
• Loading multiple sources of data</br>
• Consolidating data for analysis</br>
• Reshaping and joining datasets</br>
• Dealing with missing values, duplicates and outliers</br>
• Cleaning strings


# Why is data cleaning important?

## *'Garbage in leads to garbage out'*:
• Estimated $3 trillion US GDP lost in 2016 - IBM</br>
• 1 in 3 business leaders did not trust the data sources  used in decision-making</br>


## *You get to know your data*:
• Understanding data through inital cleaning and exploration</br>
• Reduces the risk of incorrect assumptions</br>
• Raises relevant questions</br>
• Discovery of issues such as biases in data collection</br>
• Opportunities to problem solve for unique datasets</br>
• Setup to extract additional insight</br>
• Setup to emphasis particular questions</br>


# Project overview

## Tasks

This project centres around cleaning six dirty datasets:</br>
• Task 1 - Decathlon Events</br>
• Task 2 - Cake Ingredients</br>
• Task 3 - Seabirds Spottings</br>
• Task 4 - Sweeties Survey</br>
• Task 5 - Codebook</br>
• Task 6 - Dogs</br>

## Format

Each solution will include:</br>
• R project (`.Rproj`)</br>
• Cleaning script</br>
• Commentary, assumptions and process</br>
• Answers to questions</br>



## Folder structure 

```
raw_data
data_cleaning_scripts
clean_data
documentation_and_analysis
```